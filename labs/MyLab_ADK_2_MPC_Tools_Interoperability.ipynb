{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923064a7",
   "metadata": {},
   "source": [
    "### ** Agent-as-a-Tool  üßë‚Äçüç≥ **\n",
    "\n",
    "\n",
    "MyLab_ADK_2 ‚Äî MCP, Interoperability, and Orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9631d",
   "metadata": {},
   "source": [
    "Part 0 ‚Äî Setup & Authentication üîë\n",
    "Verify the Kernel\n",
    "\n",
    "Make sure you‚Äôre using your correct venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c40d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3\n",
      "Kernel:  /home/oem/Repos/CursoLLM/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Kernel: \", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bac3f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries are ready to go!\n",
      "‚úÖ API Key configured successfully! Let the fun begin.\n"
     ]
    }
   ],
   "source": [
    "# --- Import all necessary libraries for our entire adventure ---\n",
    "import os\n",
    "import re\n",
    "import asyncio\n",
    "from IPython.display import display, Markdown\n",
    "import google.generativeai as genai\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService, Session\n",
    "from google.genai.types import Content, Part\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"‚úÖ All libraries are ready to go!\")\n",
    "\n",
    "api_key = getpass('Enter your Google API Key: ')\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = api_key\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "print(\"‚úÖ API Key configured successfully! Let the fun begin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798fbd1",
   "metadata": {},
   "source": [
    "## 2.2 The Agent-as-a-Tool: Consulting a Specialist üßë‚Äçüç≥\n",
    "\n",
    "Why build one agent that does everything when you can build a **team of specialist agents?** The **Agent-as-a-Tool** pattern \n",
    "allows one agent to delegate a task to another agent.\n",
    "\n",
    "**Key Concept:** This is different from a sub-agent. When Agent A calls Agent B as a tool, \n",
    "Agent B's response is passed **back to Agent A**. Agent A then uses that information to form its own final \n",
    "response to the user. It's a powerful way to compose complex behaviors from simpler, focused, and reusable agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63655d79",
   "metadata": {},
   "source": [
    "### How It Works\n",
    "\n",
    "Our top-level agent, the `trip_data_concierge_agent`, acts as the **Orchestrator**. It has two tools at its disposal:\n",
    "\n",
    "1.  `call_db_agent`: A function that internally calls our `db_agent` to fetch raw data.\n",
    "2.  `call_concierge_agent`: A function that calls the `concierge_agent`.\n",
    "\n",
    "The `concierge_agent` itself has a tool: the `food_critic_agent`.\n",
    "\n",
    "The flow for a complex query is:\n",
    "\n",
    "1.  **User** asks the `trip_data_concierge_agent` for a hotel and a nearby restaurant.\n",
    "2.  The **Orchestrator** first calls `call_db_agent` to get hotel data.\n",
    "3.  The data is saved in `tool_context.state`.\n",
    "4.  The **Orchestrator** then calls `call_concierge_agent`, which retrieves the hotel data from the context.\n",
    "5.  The `concierge_agent` receives the request and decides it needs to use its own tool, the `food_critic_agent`.\n",
    "6.  The `food_critic_agent` provides a witty recommendation.\n",
    "7.  The `concierge_agent` gets the critic's response and politely formats it.\n",
    "8.  This final, polished response is returned to the **Orchestrator**, which presents it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a5a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Orchestrator Agent 'trip_data_concierge' is defined and ready.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.adk.tools import ToolContext\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "\n",
    "# Assume 'db_agent' is a pre-defined NL2SQL Agent\n",
    "# For this example, we'll create placeholder agents.\n",
    "\n",
    "db_agent = Agent(\n",
    "    name=\"db_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"You are a database agent. When asked for data, return this mock JSON object: {'status': 'success', 'data': [{'name': 'The Grand Hotel', 'rating': 5, 'reviews': 450}, {'name': 'Seaside Inn', 'rating': 4, 'reviews': 620}]}\"\n",
    "    )\n",
    "\n",
    "# --- 1. Define the Specialist Agents ---\n",
    "\n",
    "# The Food Critic remains the deepest specialist\n",
    "food_critic_agent = Agent(\n",
    "    name=\"food_critic_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"You are a snobby but brilliant food critic. You ONLY respond with a single, witty restaurant suggestion near the provided location.\",\n",
    ")\n",
    "\n",
    "# The Concierge knows how to use the Food Critic\n",
    "concierge_agent = Agent(\n",
    "    name=\"concierge_agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instruction=\"You are a five-star hotel concierge. If the user asks for a restaurant recommendation, you MUST use the `food_critic_agent` tool. Present the opinion to the user politely.\",\n",
    "    tools=[AgentTool(agent=food_critic_agent)]\n",
    ")\n",
    "\n",
    "\n",
    "# --- 2. Define the Tools for the Orchestrator ---\n",
    "\n",
    "async def call_db_agent(\n",
    "    question: str,\n",
    "    tool_context: ToolContext,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use this tool FIRST to connect to the database and retrieve a list of places, like hotels or landmarks.\n",
    "    \"\"\"\n",
    "    print(\"--- TOOL CALL: call_db_agent ---\")\n",
    "    agent_tool = AgentTool(agent=db_agent)\n",
    "    db_agent_output = await agent_tool.run_async(\n",
    "        args={\"request\": question}, tool_context=tool_context\n",
    "    )\n",
    "    # Store the retrieved data in the context's state\n",
    "    tool_context.state[\"retrieved_data\"] = db_agent_output\n",
    "    return db_agent_output\n",
    "\n",
    "\n",
    "async def call_concierge_agent(\n",
    "    question: str,\n",
    "    tool_context: ToolContext,\n",
    "):\n",
    "    \"\"\"\n",
    "    After getting data with call_db_agent, use this tool to get travel advice, opinions, or recommendations.\n",
    "    \"\"\"\n",
    "    print(\"--- TOOL CALL: call_concierge_agent ---\")\n",
    "    # Retrieve the data fetched by the previous tool\n",
    "    input_data = tool_context.state.get(\"retrieved_data\", \"No data found.\")\n",
    "\n",
    "    # Formulate a new prompt for the concierge, giving it the data context\n",
    "    question_with_data = f\"\"\"\n",
    "    Context: The database returned the following data: {input_data}\n",
    "\n",
    "    User's Request: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    agent_tool = AgentTool(agent=concierge_agent)\n",
    "    concierge_output = await agent_tool.run_async(\n",
    "        args={\"request\": question_with_data}, tool_context=tool_context\n",
    "    )\n",
    "    return concierge_output\n",
    "\n",
    "\n",
    "# --- 3. Define the Top-Level Orchestrator Agent ---\n",
    "\n",
    "trip_data_concierge_agent = Agent(\n",
    "    name=\"trip_data_concierge\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    description=\"Top-level agent that queries a database for travel data, then calls a concierge agent for recommendations.\",\n",
    "    tools=[call_db_agent, call_concierge_agent],\n",
    "    instruction=\"\"\"\n",
    "    You are a master travel planner who uses data to make recommendations.\n",
    "\n",
    "    1.  **ALWAYS start with the `call_db_agent` tool** to fetch a list of places (like hotels) that match the user's criteria.\n",
    "\n",
    "    2.  After you have the data, **use the `call_concierge_agent` tool** to answer any follow-up questions for recommendations, opinions, or advice related to the data you just found.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Orchestrator Agent '{trip_data_concierge_agent.name}' is defined and ready.\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06f285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai.types import Content, Part\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "session_service = InMemorySessionService()\n",
    "my_user_id = \"user-001\"\n",
    "\n",
    "async def run_agent_query(agent, query: str, session, user_id: str):\n",
    "    runner = Runner(agent=agent, session_service=session_service, app_name=agent.name)\n",
    "    final = \"\"\n",
    "    async for event in runner.run_async(\n",
    "        user_id=user_id,\n",
    "        session_id=session.id,\n",
    "        new_message=Content(parts=[Part(text=query)], role=\"user\")\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            final = event.content.parts[0].text\n",
    "    display(Markdown(final))\n",
    "    return final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa0c171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: Find the top-rated hotels in Venice from the database, then suggest a dinner spot near the one with the most reviews.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['thought_signature', 'function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The top-rated hotels in Venice are The Grand Hotel (5 stars, 450 reviews) and Seaside Inn (4 stars, 620 reviews). I recommend C&O Trattoria for a dinner spot near Seaside Inn. Their garlic knots are legendary!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Let's test the Trip Data Concierge Agent ---\n",
    "\n",
    "async def run_trip_data_concierge():\n",
    "    session = await session_service.create_session(\n",
    "        app_name=trip_data_concierge_agent.name, \n",
    "        user_id=my_user_id\n",
    "        )\n",
    "    query = (\"Find the top-rated hotels in Venice from the database, \"\n",
    "             \"then suggest a dinner spot near the one with the most reviews.\")\n",
    "    print(\"User Query:\", query)\n",
    "\n",
    "    # We call our existing helper function with the top-level orchestrator agent\n",
    "    await run_agent_query(trip_data_concierge_agent, query, session, my_user_id)\n",
    "\n",
    "# Run the test:\n",
    "await run_trip_data_concierge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc41c2",
   "metadata": {},
   "source": [
    "## üß© Key Concepts Recap: Multi-Agent Orchestration with Shared Context\n",
    "\n",
    "### **Agent**\n",
    "An **Agent** is an autonomous reasoning unit that can:\n",
    "- Understand instructions (via `instruction` or `description`).\n",
    "- Call tools (functions, APIs, or other agents) to complete tasks.\n",
    "- Use an underlying LLM (`model` parameter) to generate responses.\n",
    "\n",
    "---\n",
    "\n",
    "### **AgentTool**\n",
    "- A **wrapper** that allows an Agent to be used **as a tool** by another Agent.\n",
    "- Enables composition: one Agent can call another just like a function.\n",
    "- Example: `concierge_agent` uses `food_critic_agent` via `AgentTool`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tool Function**\n",
    "- A regular Python async function annotated with a docstring that describes:\n",
    "  - What it does.\n",
    "  - When it should be called.\n",
    "- Registered in the top-level Agent's `tools` list.\n",
    "- Can:\n",
    "  - Call APIs.\n",
    "  - Run other Agents.\n",
    "  - Store intermediate results in `ToolContext`.\n",
    "\n",
    "---\n",
    "\n",
    "### **ToolContext**\n",
    "- A temporary **shared state** object passed between tools **in a single user turn**.\n",
    "- Behaves like a dictionary (`tool_context.state`).\n",
    "- Used for:\n",
    "  - Passing data from one tool to another.\n",
    "  - Avoiding repeated API calls.\n",
    "- **Ephemeral**: state is cleared after the user turn ends.\n",
    "\n",
    "---\n",
    "\n",
    "### **Orchestrator Agent**\n",
    "- A **top-level agent** that coordinates multiple steps and tools.\n",
    "- Holds the workflow logic:\n",
    "  1. Call `call_db_agent` to fetch data.\n",
    "  2. Call `call_concierge_agent` to get recommendations based on that data.\n",
    "- Tools can be other agents (via `AgentTool`) or custom functions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Session & SessionService**\n",
    "- **Session**: Tracks conversation history and context over multiple turns.\n",
    "- **SessionService**: Creates and manages sessions.\n",
    "- In our example:\n",
    "  - `session_service.create_session()` starts a fresh session.\n",
    "  - We pass it to `run_agent_query()` so the agent can keep track of the conversation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Execution Flow Recap**\n",
    "1. **User query** ‚Üí sent to `trip_data_concierge_agent`.\n",
    "2. **First tool** (`call_db_agent`) runs ‚Üí gets data ‚Üí saves it in `tool_context.state`.\n",
    "3. **Second tool** (`call_concierge_agent`) reads saved data ‚Üí reformulates prompt ‚Üí calls `concierge_agent`.\n",
    "4. **Concierge agent** calls **food critic agent** internally via `AgentTool`.\n",
    "5. **Final response** is returned to the user in a single step.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ **Key Benefits**:\n",
    "- Modular: each Agent focuses on one skill.\n",
    "- Reusable: Agents can be wrapped as tools.\n",
    "- Context-passing: `ToolContext` avoids messy global variables.\n",
    "- Clear orchestration: top-level Agent decides the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abed22b",
   "metadata": {},
   "source": [
    "### ** Agent with a Memory - The Adaptive Planner üó∫Ô∏è **\n",
    "\n",
    "In this part, we will build a **multi-day trip planner** that not only remembers previous conversation turns but also adapts to user feedback.  \n",
    "The main difference from earlier parts is **memory management**: by reusing the same `Session` object across multiple turns, the agent maintains context and can adapt its plan accordingly.\n",
    "\n",
    "---\n",
    "\n",
    "### Concept: Why Memory Matters in Conversational Agents\n",
    "\n",
    "When building conversational AI:\n",
    "- **Without memory** ‚Üí Each turn is independent, no context is carried forward.  \n",
    "- **With memory** ‚Üí The agent can recall past user inputs, previous outputs, and adapt based on feedback.  \n",
    "- The **Session** object acts like the agent‚Äôs ‚Äúshort-term memory‚Äù, storing relevant state between turns.\n",
    "\n",
    "---\n",
    "\n",
    "### Agent Definition ‚Äì Adaptive Multi-Day Trip Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Definition: The Adaptive Planner ---\n",
    "\n",
    "def create_multi_day_trip_agent():\n",
    "    \"\"\" Create the PRogressive Multi-Day Planner agent\"\"\"\n",
    "    return Agent(\n",
    "        name=\"multi_day_trip_agent\",\n",
    "        model=\"gemini-2.5-flash\",\n",
    "\n",
    "        description=\"Agent that progressively plans a multi-day trip, remembering previous days and adapting to user feedback\",\n",
    "        instruction=\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ec68d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
